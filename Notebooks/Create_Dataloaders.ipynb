{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1c7208c",
   "metadata": {},
   "source": [
    "# Creating Dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38313aff",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10f3e599",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib.metadata import version\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67a68da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib.metadata import version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22b46b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas version: 2.3.1\n",
      "numpy version: 1.23.5\n",
      "seaborn version: 0.13.2\n",
      "matplotlib version: 3.10.5\n",
      "torch version: 2.5.1\n",
      "joblib version: 1.5.1\n"
     ]
    }
   ],
   "source": [
    "list = ['pandas', 'numpy', 'seaborn', 'matplotlib', 'torch', 'joblib']\n",
    "for package in list:\n",
    "    try:\n",
    "        print(f\"{package} version: {version(package)}\") # Raises PackageNotFoundError if not found\n",
    "    except:\n",
    "         print(f\"❌ Package '{package}' not found. Please install it.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbefac4",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab61f61",
   "metadata": {},
   "source": [
    "### Prepare Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba3cf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = Path(\"../Data\")\n",
    "# OIL_PATH_ORIGINAL = DATA_ROOT / \"OIL_Dataset_1984-2025.csv\"     # Set the data source path\n",
    "DATA_CLEAN = \"OIL_DATASET.csv\"\n",
    "DATA_CLEAN_PATH = DATA_ROOT / DATA_CLEAN\n",
    "\n",
    "# MODEL_ROOT = Path(\"../Models\")  # To store trained models and scalers\n",
    "\n",
    "# TRAIN_FEATURE_SCALER = \"train_feature_scaler.joblib\"\n",
    "# TRAIN_LABEL_SCALER = \"train_label_scaler.joblib\"\n",
    "\n",
    "# TRAIN_FEATURE_SCALER_PATH = MODEL_ROOT / TRAIN_FEATURE_SCALER\n",
    "# TRAIN_LABEL_SCALER_PATH = MODEL_ROOT / TRAIN_LABEL_SCALER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab276b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file detected, reading from '..\\Data'\n"
     ]
    }
   ],
   "source": [
    "# Login using e.g. `huggingface-cli login` to access this dataset\n",
    "\n",
    "if DATA_CLEAN_PATH.exists():\n",
    "    print(f\"CSV file detected, reading from '{DATA_ROOT}'\")\n",
    "    df = pd.read_csv(DATA_CLEAN_PATH)\n",
    "\n",
    "else:\n",
    "    print(f\"Downloading CSV file from HuggingFace\")\n",
    "    os.makedirs(DATA_ROOT, exist_ok=True)\n",
    "    df = pd.read_csv(\"hf://datasets/MaxPrestige/CRUDE_OIL_PRICES/Data/OIL_DATASET.csv\")\n",
    "    df.to_csv(DATA_CLEAN_PATH, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9f4d48",
   "metadata": {},
   "source": [
    "#### File Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f4471e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [DATA_CLEAN_PATH]\n",
    "\n",
    "try:\n",
    "    for path in paths:\n",
    "        if not path.exists():\n",
    "            raise FileNotFoundError(f\"The file '{path}' does not exist.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd070a82",
   "metadata": {},
   "source": [
    "#### Reading File to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2532d9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_CLEAN_PATH, parse_dates=['Date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e2cd8704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.indexes.base.Index"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67bf8bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_col = \"Close\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549c8620",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "298b1eab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>67.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Close\n",
       "0  66.63\n",
       "1  67.31\n",
       "2  67.82\n",
       "3  67.61\n",
       "4  67.82"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "429099d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of df_features: (6364, 22)\n",
      "shape of df_labels: (6364, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"shape of df_features: {df_features.shape}\")\n",
    "print(f\"shape of df_labels: {df_labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f29296ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>California_Crude_Oil_First_Purchase_Price_$/bbl</th>\n",
       "      <th>Texas_Crude_Oil_First_Purchase_Price_$/bbl</th>\n",
       "      <th>US_Crude_Oil_First_Purchase_Price_$/bbl</th>\n",
       "      <th>US_Imports_from_Canada_of_Crude_Oil_Mbbl/d</th>\n",
       "      <th>US_Imports_from_Colombia_of_Crude_Oil_Mbbl/d</th>\n",
       "      <th>US_Imports_from_United_Kingdom_of_Crude_Oil_Mbbl/d</th>\n",
       "      <th>US_Imports_from_Mexico_of_Crude_Oil_Mbbl/d</th>\n",
       "      <th>...</th>\n",
       "      <th>US_Imports_of_Crude_Oil_Mbbl/d</th>\n",
       "      <th>US_Exports_to_Canada_of_Crude_Oil_Mbbl/d</th>\n",
       "      <th>US_Exports_of_Crude_Oil_Mbbl/d</th>\n",
       "      <th>US_Net_Imports_from_Canada_of_Crude_Oil_Mbbl/d</th>\n",
       "      <th>US_Net_Imports_from_Colombia_of_Crude_Oil_Mbbl/d</th>\n",
       "      <th>US_Net_Imports_from_Mexico_of_Crude_Oil_Mbbl/d</th>\n",
       "      <th>US_Net_Imports_from_United_Kingdom_of_Crude_Oil_Mbbl/d</th>\n",
       "      <th>US_Net_Imports_from_OPEC_Countries_of_Crude_Oil_Mbbl/d</th>\n",
       "      <th>US_Net_Imports_from_Non-OPEC_Countries_of_Crude_Oil_Mbbl/d</th>\n",
       "      <th>US_Net_Imports_of_Crude_Oil_Mbbl/d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67.33</td>\n",
       "      <td>67.20</td>\n",
       "      <td>65.92</td>\n",
       "      <td>62.41</td>\n",
       "      <td>60.56</td>\n",
       "      <td>59.94</td>\n",
       "      <td>3814.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>431.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6259.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>3629.0</td>\n",
       "      <td>3596.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>431.0</td>\n",
       "      <td>-93.0</td>\n",
       "      <td>697.0</td>\n",
       "      <td>1934.0</td>\n",
       "      <td>2631.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.91</td>\n",
       "      <td>68.42</td>\n",
       "      <td>67.20</td>\n",
       "      <td>62.41</td>\n",
       "      <td>60.56</td>\n",
       "      <td>59.94</td>\n",
       "      <td>3814.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>431.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6259.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>3629.0</td>\n",
       "      <td>3596.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>431.0</td>\n",
       "      <td>-93.0</td>\n",
       "      <td>697.0</td>\n",
       "      <td>1934.0</td>\n",
       "      <td>2631.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67.77</td>\n",
       "      <td>69.05</td>\n",
       "      <td>67.38</td>\n",
       "      <td>62.41</td>\n",
       "      <td>60.56</td>\n",
       "      <td>59.94</td>\n",
       "      <td>3814.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>431.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6259.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>3629.0</td>\n",
       "      <td>3596.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>431.0</td>\n",
       "      <td>-93.0</td>\n",
       "      <td>697.0</td>\n",
       "      <td>1934.0</td>\n",
       "      <td>2631.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67.88</td>\n",
       "      <td>68.78</td>\n",
       "      <td>67.32</td>\n",
       "      <td>62.41</td>\n",
       "      <td>60.56</td>\n",
       "      <td>59.94</td>\n",
       "      <td>3814.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>431.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6259.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>3629.0</td>\n",
       "      <td>3596.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>431.0</td>\n",
       "      <td>-93.0</td>\n",
       "      <td>697.0</td>\n",
       "      <td>1934.0</td>\n",
       "      <td>2631.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68.37</td>\n",
       "      <td>70.20</td>\n",
       "      <td>66.82</td>\n",
       "      <td>62.41</td>\n",
       "      <td>60.56</td>\n",
       "      <td>59.94</td>\n",
       "      <td>3814.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>431.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6259.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>3629.0</td>\n",
       "      <td>3596.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>431.0</td>\n",
       "      <td>-93.0</td>\n",
       "      <td>697.0</td>\n",
       "      <td>1934.0</td>\n",
       "      <td>2631.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Open   High    Low  California_Crude_Oil_First_Purchase_Price_$/bbl  \\\n",
       "0  67.33  67.20  65.92                                            62.41   \n",
       "1  67.91  68.42  67.20                                            62.41   \n",
       "2  67.77  69.05  67.38                                            62.41   \n",
       "3  67.88  68.78  67.32                                            62.41   \n",
       "4  68.37  70.20  66.82                                            62.41   \n",
       "\n",
       "   Texas_Crude_Oil_First_Purchase_Price_$/bbl  \\\n",
       "0                                       60.56   \n",
       "1                                       60.56   \n",
       "2                                       60.56   \n",
       "3                                       60.56   \n",
       "4                                       60.56   \n",
       "\n",
       "   US_Crude_Oil_First_Purchase_Price_$/bbl  \\\n",
       "0                                    59.94   \n",
       "1                                    59.94   \n",
       "2                                    59.94   \n",
       "3                                    59.94   \n",
       "4                                    59.94   \n",
       "\n",
       "   US_Imports_from_Canada_of_Crude_Oil_Mbbl/d  \\\n",
       "0                                      3814.0   \n",
       "1                                      3814.0   \n",
       "2                                      3814.0   \n",
       "3                                      3814.0   \n",
       "4                                      3814.0   \n",
       "\n",
       "   US_Imports_from_Colombia_of_Crude_Oil_Mbbl/d  \\\n",
       "0                                         223.0   \n",
       "1                                         223.0   \n",
       "2                                         223.0   \n",
       "3                                         223.0   \n",
       "4                                         223.0   \n",
       "\n",
       "   US_Imports_from_United_Kingdom_of_Crude_Oil_Mbbl/d  \\\n",
       "0                                               81.0    \n",
       "1                                               81.0    \n",
       "2                                               81.0    \n",
       "3                                               81.0    \n",
       "4                                               81.0    \n",
       "\n",
       "   US_Imports_from_Mexico_of_Crude_Oil_Mbbl/d  ...  \\\n",
       "0                                       431.0  ...   \n",
       "1                                       431.0  ...   \n",
       "2                                       431.0  ...   \n",
       "3                                       431.0  ...   \n",
       "4                                       431.0  ...   \n",
       "\n",
       "   US_Imports_of_Crude_Oil_Mbbl/d  US_Exports_to_Canada_of_Crude_Oil_Mbbl/d  \\\n",
       "0                          6259.0                                     218.0   \n",
       "1                          6259.0                                     218.0   \n",
       "2                          6259.0                                     218.0   \n",
       "3                          6259.0                                     218.0   \n",
       "4                          6259.0                                     218.0   \n",
       "\n",
       "   US_Exports_of_Crude_Oil_Mbbl/d  \\\n",
       "0                          3629.0   \n",
       "1                          3629.0   \n",
       "2                          3629.0   \n",
       "3                          3629.0   \n",
       "4                          3629.0   \n",
       "\n",
       "   US_Net_Imports_from_Canada_of_Crude_Oil_Mbbl/d  \\\n",
       "0                                          3596.0   \n",
       "1                                          3596.0   \n",
       "2                                          3596.0   \n",
       "3                                          3596.0   \n",
       "4                                          3596.0   \n",
       "\n",
       "   US_Net_Imports_from_Colombia_of_Crude_Oil_Mbbl/d  \\\n",
       "0                                             207.0   \n",
       "1                                             207.0   \n",
       "2                                             207.0   \n",
       "3                                             207.0   \n",
       "4                                             207.0   \n",
       "\n",
       "   US_Net_Imports_from_Mexico_of_Crude_Oil_Mbbl/d  \\\n",
       "0                                           431.0   \n",
       "1                                           431.0   \n",
       "2                                           431.0   \n",
       "3                                           431.0   \n",
       "4                                           431.0   \n",
       "\n",
       "   US_Net_Imports_from_United_Kingdom_of_Crude_Oil_Mbbl/d  \\\n",
       "0                                              -93.0        \n",
       "1                                              -93.0        \n",
       "2                                              -93.0        \n",
       "3                                              -93.0        \n",
       "4                                              -93.0        \n",
       "\n",
       "   US_Net_Imports_from_OPEC_Countries_of_Crude_Oil_Mbbl/d  \\\n",
       "0                                              697.0        \n",
       "1                                              697.0        \n",
       "2                                              697.0        \n",
       "3                                              697.0        \n",
       "4                                              697.0        \n",
       "\n",
       "   US_Net_Imports_from_Non-OPEC_Countries_of_Crude_Oil_Mbbl/d  \\\n",
       "0                                             1934.0            \n",
       "1                                             1934.0            \n",
       "2                                             1934.0            \n",
       "3                                             1934.0            \n",
       "4                                             1934.0            \n",
       "\n",
       "   US_Net_Imports_of_Crude_Oil_Mbbl/d  \n",
       "0                              2631.0  \n",
       "1                              2631.0  \n",
       "2                              2631.0  \n",
       "3                              2631.0  \n",
       "4                              2631.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "190ea6ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    66.63\n",
       "1    67.31\n",
       "2    67.82\n",
       "3    67.61\n",
       "4    67.82\n",
       "Name: Close, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09f7d75",
   "metadata": {},
   "source": [
    "## Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9cdaff40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Features: (5727, 22)\n",
      "Train Labels: (5727, 1)\n",
      "validation Features: (318, 22)\n",
      "validation Labels: (318, 1)\n",
      "test Features: (319, 22)\n",
      "test Labels: (319, 1)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c6e1adb",
   "metadata": {},
   "source": [
    "## Scaling The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e6e953ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_splits_dir = \"DataSplits\"\n",
    "scaler_dir = \"Scalers\"\n",
    "DATA_SPLITS_DIR = DATA_ROOT / data_splits_dir\n",
    "SCALER_DIR = DATA_ROOT / scaler_dir\n",
    "\n",
    "TRAIN_DATA_PATH = DATA_SPLITS_DIR / \"train.csv\"\n",
    "TEST_DATA_PATH = DATA_SPLITS_DIR / \"test.csv\"\n",
    "VALIDATION_DATA_PATH = DATA_SPLITS_DIR / \"val.csv\"\n",
    "FEATURE_SCALER_PATH = SCALER_DIR / \"feature-scaler.joblib\"\n",
    "LABEL_SCALER_PATH = SCALER_DIR / \"label-scaler.joblib\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b2b450f",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_col = \"Close\"\n",
    "extra_dropped_cols = 'Date'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20303fe8",
   "metadata": {},
   "source": [
    "### Notes\n",
    "Only fit the scalers on the training data to prevent any data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6f64aa25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets not found in '..\\Data\\DataSplits' or incomplete. Generating datasets...\n",
      "Train Features: (5727, 22)\n",
      "Train Labels: (5727, 1)\n",
      "validation Features: (318, 22)\n",
      "validation Labels: (318, 1)\n",
      "test Features: (319, 22)\n",
      "test Labels: (319, 1)\n",
      "Feature scaler stored in: (..\\Data\\Scalers\\feature-scaler.joblib)\n",
      "Label scaler stored in: (..\\Data\\Scalers\\label-scaler.joblib)\n",
      "Train Features Scaled Shape: (5727, 22)\n",
      "Train Labels Scaled Shape: (319, 1)\n",
      "validation Features Scaled Shape: (318, 22)\n",
      "validation Labels: (318, 1)\n",
      "test Features Scaled Shape: (319, 22)\n",
      "test Labels Scaled Shape: (319, 1)\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(TRAIN_DATA_PATH) and os.path.exists(TEST_DATA_PATH) and os.path.exists(VALIDATION_DATA_PATH) :\n",
    "    print(f\"Train, Test, and Validation csv datasets detected in '{DATA_SPLITS_DIR}', skipping generation\")\n",
    "    try:\n",
    "        feature_scaler = joblib.load(FEATURE_SCALER_PATH)\n",
    "        label_scaler = joblib.load(LABEL_SCALER_PATH)\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"An unexpected error occurred when loading scalers: {e}\")\n",
    "else:\n",
    "    print(f\"Datasets not found in '{DATA_SPLITS_DIR}' or incomplete. Generating datasets...\")\n",
    "    os.makedirs(MODEL_ROOT, exist_ok=True)\n",
    "    os.makedirs(DATA_SPLITS_DIR, exist_ok=True)     # Create the Data Splits Parent Directory\n",
    "    os.makedirs(SCALER_DIR, exist_ok=True)     # Create the Data Splits Parent Directory\n",
    "\n",
    "    \n",
    "    df_features = df.drop(columns=[label_col, extra_dropped_cols], inplace=False)\n",
    "    df_labels = df[[label_col]]     # Instead of returning a pandas Series using \"[]\", return a dataframe using the \"[[]]\" to get a shape with (-1,1)\n",
    "\n",
    "    feature_scaler = MinMaxScaler()\n",
    "    label_scaler = MinMaxScaler()\n",
    "\n",
    "    # Split the whole pandas DataFrame into smaller DataFrames\n",
    "    X_train, X_inter, Y_train, Y_inter = train_test_split(df_features, df_labels, test_size=0.1, random_state=42)\n",
    "    X_validation, X_test, Y_validation, Y_test = train_test_split(X_inter, Y_inter, test_size=0.5, random_state=42)\n",
    "\n",
    "    print(f\"Train Features: {X_train.shape}\")\n",
    "    print(f\"Train Labels: {Y_train.shape}\")\n",
    "    print(f\"validation Features: {X_validation.shape}\")\n",
    "    print(f\"validation Labels: {Y_validation.shape}\")\n",
    "    print(f\"test Features: {X_test.shape}\")\n",
    "    print(f\"test Labels: {Y_test.shape}\")\n",
    "\n",
    "    feature_scaler.fit(X_train)\n",
    "    label_scaler.fit(Y_train)\n",
    "\n",
    "    # Save the fitted scaler object\n",
    "    try:\n",
    "        joblib.dump(feature_scaler, FEATURE_SCALER_PATH)\n",
    "        print(f\"Feature scaler stored in: ({FEATURE_SCALER_PATH})\")\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"An unexpected error occurred when saving Feature Scaler: {e}\")\n",
    "    try:\n",
    "        joblib.dump(label_scaler, LABEL_SCALER_PATH)\n",
    "        print(f\"Label scaler stored in: ({LABEL_SCALER_PATH})\")\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"An unexpected error occurred when saving Label Scaler: {e}\")\n",
    "\n",
    "\n",
    "# Scale the rest of the data; returns numpy arrays\n",
    "X_train_scaled = feature_scaler.transform(X_train)\n",
    "Y_train_scaled = label_scaler.transform(Y_train)\n",
    "X_validation_scaled = feature_scaler.transform(X_validation)\n",
    "Y_validation_scaled = label_scaler.transform(Y_validation)\n",
    "X_test_scaled = feature_scaler.transform(X_test)\n",
    "Y_test_scaled = label_scaler.transform(Y_test)\n",
    "\n",
    "\n",
    "print(f\"Train Features Scaled Shape: {X_train_scaled.shape}\")\n",
    "print(f\"Train Labels Scaled Shape: {Y_test_scaled.shape}\")\n",
    "print(f\"validation Features Scaled Shape: {X_validation_scaled.shape}\")\n",
    "print(f\"validation Labels: {Y_validation_scaled.shape}\")\n",
    "print(f\"test Features Scaled Shape: {X_test_scaled.shape}\")\n",
    "print(f\"test Labels Scaled Shape: {Y_test_scaled.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "628a2724",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df_features.columns\n",
    "labels = df_labels.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7e384aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df = pd.DataFrame(X_train_scaled, columns=features)\n",
    "X_test_df = pd.DataFrame(X_test_scaled, columns=features)\n",
    "X_validation_df = pd.DataFrame(X_validation_scaled, columns=features)\n",
    "Y_train_df = pd.DataFrame(Y_train_scaled, columns=labels)\n",
    "Y_test_df = pd.DataFrame(Y_test_scaled, columns=labels)\n",
    "Y_validation_df = pd.DataFrame(Y_validation_scaled, columns=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f9cf0ea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>California_Crude_Oil_First_Purchase_Price_$/bbl</th>\n",
       "      <th>Texas_Crude_Oil_First_Purchase_Price_$/bbl</th>\n",
       "      <th>US_Crude_Oil_First_Purchase_Price_$/bbl</th>\n",
       "      <th>US_Imports_from_Canada_of_Crude_Oil_Mbbl/d</th>\n",
       "      <th>US_Imports_from_Colombia_of_Crude_Oil_Mbbl/d</th>\n",
       "      <th>US_Imports_from_United_Kingdom_of_Crude_Oil_Mbbl/d</th>\n",
       "      <th>US_Imports_from_Mexico_of_Crude_Oil_Mbbl/d</th>\n",
       "      <th>...</th>\n",
       "      <th>US_Imports_of_Crude_Oil_Mbbl/d</th>\n",
       "      <th>US_Exports_to_Canada_of_Crude_Oil_Mbbl/d</th>\n",
       "      <th>US_Exports_of_Crude_Oil_Mbbl/d</th>\n",
       "      <th>US_Net_Imports_from_Canada_of_Crude_Oil_Mbbl/d</th>\n",
       "      <th>US_Net_Imports_from_Colombia_of_Crude_Oil_Mbbl/d</th>\n",
       "      <th>US_Net_Imports_from_Mexico_of_Crude_Oil_Mbbl/d</th>\n",
       "      <th>US_Net_Imports_from_United_Kingdom_of_Crude_Oil_Mbbl/d</th>\n",
       "      <th>US_Net_Imports_from_OPEC_Countries_of_Crude_Oil_Mbbl/d</th>\n",
       "      <th>US_Net_Imports_from_Non-OPEC_Countries_of_Crude_Oil_Mbbl/d</th>\n",
       "      <th>US_Net_Imports_of_Crude_Oil_Mbbl/d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.816492</td>\n",
       "      <td>0.818934</td>\n",
       "      <td>0.827768</td>\n",
       "      <td>0.892130</td>\n",
       "      <td>0.740693</td>\n",
       "      <td>0.769353</td>\n",
       "      <td>0.404693</td>\n",
       "      <td>0.757519</td>\n",
       "      <td>0.016026</td>\n",
       "      <td>0.465409</td>\n",
       "      <td>...</td>\n",
       "      <td>0.597405</td>\n",
       "      <td>0.113924</td>\n",
       "      <td>0.015243</td>\n",
       "      <td>0.431900</td>\n",
       "      <td>0.757519</td>\n",
       "      <td>0.465409</td>\n",
       "      <td>0.445348</td>\n",
       "      <td>0.629321</td>\n",
       "      <td>0.764043</td>\n",
       "      <td>0.750305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.338057</td>\n",
       "      <td>0.338331</td>\n",
       "      <td>0.337164</td>\n",
       "      <td>0.406034</td>\n",
       "      <td>0.329044</td>\n",
       "      <td>0.340567</td>\n",
       "      <td>0.813565</td>\n",
       "      <td>0.528195</td>\n",
       "      <td>0.091346</td>\n",
       "      <td>0.255066</td>\n",
       "      <td>...</td>\n",
       "      <td>0.301718</td>\n",
       "      <td>0.791139</td>\n",
       "      <td>0.591026</td>\n",
       "      <td>0.734409</td>\n",
       "      <td>0.490602</td>\n",
       "      <td>0.255066</td>\n",
       "      <td>0.247516</td>\n",
       "      <td>0.206516</td>\n",
       "      <td>0.382313</td>\n",
       "      <td>0.274167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.180256</td>\n",
       "      <td>0.192040</td>\n",
       "      <td>0.185122</td>\n",
       "      <td>0.174300</td>\n",
       "      <td>0.215389</td>\n",
       "      <td>0.204074</td>\n",
       "      <td>0.094503</td>\n",
       "      <td>0.174812</td>\n",
       "      <td>0.472756</td>\n",
       "      <td>0.844864</td>\n",
       "      <td>...</td>\n",
       "      <td>0.878655</td>\n",
       "      <td>0.045886</td>\n",
       "      <td>0.006011</td>\n",
       "      <td>0.101434</td>\n",
       "      <td>0.174812</td>\n",
       "      <td>0.844864</td>\n",
       "      <td>0.702800</td>\n",
       "      <td>0.833303</td>\n",
       "      <td>0.852478</td>\n",
       "      <td>0.925479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.069299</td>\n",
       "      <td>0.068315</td>\n",
       "      <td>0.077419</td>\n",
       "      <td>0.068157</td>\n",
       "      <td>0.077029</td>\n",
       "      <td>0.065633</td>\n",
       "      <td>0.065574</td>\n",
       "      <td>0.304511</td>\n",
       "      <td>0.969551</td>\n",
       "      <td>0.790356</td>\n",
       "      <td>...</td>\n",
       "      <td>0.736659</td>\n",
       "      <td>0.006329</td>\n",
       "      <td>0.000644</td>\n",
       "      <td>0.078136</td>\n",
       "      <td>0.304511</td>\n",
       "      <td>0.790356</td>\n",
       "      <td>0.982836</td>\n",
       "      <td>0.624796</td>\n",
       "      <td>0.930224</td>\n",
       "      <td>0.842210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.721642</td>\n",
       "      <td>0.720556</td>\n",
       "      <td>0.725268</td>\n",
       "      <td>0.762177</td>\n",
       "      <td>0.619317</td>\n",
       "      <td>0.659522</td>\n",
       "      <td>0.325940</td>\n",
       "      <td>0.731203</td>\n",
       "      <td>0.014423</td>\n",
       "      <td>0.468903</td>\n",
       "      <td>...</td>\n",
       "      <td>0.528143</td>\n",
       "      <td>0.113924</td>\n",
       "      <td>0.015243</td>\n",
       "      <td>0.344086</td>\n",
       "      <td>0.731203</td>\n",
       "      <td>0.468903</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.664796</td>\n",
       "      <td>0.652284</td>\n",
       "      <td>0.708338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Open      High       Low  \\\n",
       "0  0.816492  0.818934  0.827768   \n",
       "1  0.338057  0.338331  0.337164   \n",
       "2  0.180256  0.192040  0.185122   \n",
       "3  0.069299  0.068315  0.077419   \n",
       "4  0.721642  0.720556  0.725268   \n",
       "\n",
       "   California_Crude_Oil_First_Purchase_Price_$/bbl  \\\n",
       "0                                         0.892130   \n",
       "1                                         0.406034   \n",
       "2                                         0.174300   \n",
       "3                                         0.068157   \n",
       "4                                         0.762177   \n",
       "\n",
       "   Texas_Crude_Oil_First_Purchase_Price_$/bbl  \\\n",
       "0                                    0.740693   \n",
       "1                                    0.329044   \n",
       "2                                    0.215389   \n",
       "3                                    0.077029   \n",
       "4                                    0.619317   \n",
       "\n",
       "   US_Crude_Oil_First_Purchase_Price_$/bbl  \\\n",
       "0                                 0.769353   \n",
       "1                                 0.340567   \n",
       "2                                 0.204074   \n",
       "3                                 0.065633   \n",
       "4                                 0.659522   \n",
       "\n",
       "   US_Imports_from_Canada_of_Crude_Oil_Mbbl/d  \\\n",
       "0                                    0.404693   \n",
       "1                                    0.813565   \n",
       "2                                    0.094503   \n",
       "3                                    0.065574   \n",
       "4                                    0.325940   \n",
       "\n",
       "   US_Imports_from_Colombia_of_Crude_Oil_Mbbl/d  \\\n",
       "0                                      0.757519   \n",
       "1                                      0.528195   \n",
       "2                                      0.174812   \n",
       "3                                      0.304511   \n",
       "4                                      0.731203   \n",
       "\n",
       "   US_Imports_from_United_Kingdom_of_Crude_Oil_Mbbl/d  \\\n",
       "0                                           0.016026    \n",
       "1                                           0.091346    \n",
       "2                                           0.472756    \n",
       "3                                           0.969551    \n",
       "4                                           0.014423    \n",
       "\n",
       "   US_Imports_from_Mexico_of_Crude_Oil_Mbbl/d  ...  \\\n",
       "0                                    0.465409  ...   \n",
       "1                                    0.255066  ...   \n",
       "2                                    0.844864  ...   \n",
       "3                                    0.790356  ...   \n",
       "4                                    0.468903  ...   \n",
       "\n",
       "   US_Imports_of_Crude_Oil_Mbbl/d  US_Exports_to_Canada_of_Crude_Oil_Mbbl/d  \\\n",
       "0                        0.597405                                  0.113924   \n",
       "1                        0.301718                                  0.791139   \n",
       "2                        0.878655                                  0.045886   \n",
       "3                        0.736659                                  0.006329   \n",
       "4                        0.528143                                  0.113924   \n",
       "\n",
       "   US_Exports_of_Crude_Oil_Mbbl/d  \\\n",
       "0                        0.015243   \n",
       "1                        0.591026   \n",
       "2                        0.006011   \n",
       "3                        0.000644   \n",
       "4                        0.015243   \n",
       "\n",
       "   US_Net_Imports_from_Canada_of_Crude_Oil_Mbbl/d  \\\n",
       "0                                        0.431900   \n",
       "1                                        0.734409   \n",
       "2                                        0.101434   \n",
       "3                                        0.078136   \n",
       "4                                        0.344086   \n",
       "\n",
       "   US_Net_Imports_from_Colombia_of_Crude_Oil_Mbbl/d  \\\n",
       "0                                          0.757519   \n",
       "1                                          0.490602   \n",
       "2                                          0.174812   \n",
       "3                                          0.304511   \n",
       "4                                          0.731203   \n",
       "\n",
       "   US_Net_Imports_from_Mexico_of_Crude_Oil_Mbbl/d  \\\n",
       "0                                        0.465409   \n",
       "1                                        0.255066   \n",
       "2                                        0.844864   \n",
       "3                                        0.790356   \n",
       "4                                        0.468903   \n",
       "\n",
       "   US_Net_Imports_from_United_Kingdom_of_Crude_Oil_Mbbl/d  \\\n",
       "0                                           0.445348        \n",
       "1                                           0.247516        \n",
       "2                                           0.702800        \n",
       "3                                           0.982836        \n",
       "4                                           0.444444        \n",
       "\n",
       "   US_Net_Imports_from_OPEC_Countries_of_Crude_Oil_Mbbl/d  \\\n",
       "0                                           0.629321        \n",
       "1                                           0.206516        \n",
       "2                                           0.833303        \n",
       "3                                           0.624796        \n",
       "4                                           0.664796        \n",
       "\n",
       "   US_Net_Imports_from_Non-OPEC_Countries_of_Crude_Oil_Mbbl/d  \\\n",
       "0                                           0.764043            \n",
       "1                                           0.382313            \n",
       "2                                           0.852478            \n",
       "3                                           0.930224            \n",
       "4                                           0.652284            \n",
       "\n",
       "   US_Net_Imports_of_Crude_Oil_Mbbl/d  \n",
       "0                            0.750305  \n",
       "1                            0.274167  \n",
       "2                            0.925479  \n",
       "3                            0.842210  \n",
       "4                            0.708338  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "49985a4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.818527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.345100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.198231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.073939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.729071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>0.466599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>0.689891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>0.642408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>0.467763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>0.709675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>319 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Close\n",
       "0    0.818527\n",
       "1    0.345100\n",
       "2    0.198231\n",
       "3    0.073939\n",
       "4    0.729071\n",
       "..        ...\n",
       "314  0.466599\n",
       "315  0.689891\n",
       "316  0.642408\n",
       "317  0.467763\n",
       "318  0.709675\n",
       "\n",
       "[319 rows x 1 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "340b180a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the features and labels back into a single DataFrame for each set\n",
    "train_data_frame = pd.concat([X_train_df, Y_train_df.reset_index(drop=True)], axis=1)\n",
    "test_data_frame = pd.concat([X_test_df, Y_test_df.reset_index(drop=True)], axis=1)\n",
    "validation_data_frame = pd.concat([X_validation_df, Y_validation_df.reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4c512a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the split data to csv files\n",
    "train_data_frame.to_csv(TRAIN_DATA_PATH, index=False)\n",
    "test_data_frame.to_csv(TEST_DATA_PATH, index=False)\n",
    "validation_data_frame.to_csv(VALIDATION_DATA_PATH, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8fc89a",
   "metadata": {},
   "source": [
    "## Creating Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de220668",
   "metadata": {},
   "source": [
    "### Creating Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5fdbbdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OilDataset(Dataset):\n",
    "    \"\"\"Dataset class For the OIL_DATASET\"\"\"\n",
    "    def __init__(self, csv_file=\"../Data/DataSplits/test.csv\"):\n",
    "        try:\n",
    "            self.data = pd.read_csv(csv_file)   # Assign a pandas data frame\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            raise FileNotFoundError(f\"File not found: {csv_file}\")\n",
    "\n",
    "        # Define feature and label columns\n",
    "        self.label_column = \"Close\"\n",
    "        # Remove the Date column and the label column\n",
    "        self.feature_columns = self.data.columns.drop([self.label_column])\n",
    "        \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        features = self.data.loc[index, self.feature_columns].values\n",
    "        \n",
    "        label = self.data.loc[index, self.label_column] # Extract the label for the given index\n",
    "        return (\n",
    "            torch.tensor(features, dtype=torch.float),\n",
    "            torch.tensor(label, dtype=torch.float)\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093b2922",
   "metadata": {},
   "source": [
    "### Initializing Datasets for different splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "366f95fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = OilDataset(TRAIN_DATA_PATH)\n",
    "test_dataset = OilDataset(TEST_DATA_PATH)\n",
    "val_dataset = OilDataset(VALIDATION_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "917fa508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5727"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68c4b57",
   "metadata": {},
   "source": [
    "## Creating the DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3576204f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size, workers, pin_memory, drop_last = 64, 0, True, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "edc47103",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size, num_workers=workers, pin_memory=pin_memory, drop_last=drop_last, shuffle=True)\n",
    "validation_dataloader = DataLoader(dataset=val_dataset, batch_size=batch_size, num_workers=workers, pin_memory=pin_memory, drop_last=drop_last, shuffle=False)\n",
    "test_dataloader = DataLoader(dataset=test_dataset, batch_size=batch_size, num_workers=workers, pin_memory=pin_memory, drop_last=drop_last, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "426d162a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training DataLoader has (89) batches, Test DataLoader has (4) batches, Validation DataLoader has (4) batches\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Training DataLoader has ({len(train_dataloader)}) batches, Test DataLoader has ({len(test_dataloader)}) batches, Validation DataLoader has ({len(validation_dataloader)}) batches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d7274e",
   "metadata": {},
   "source": [
    "# Complete Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9335a497",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_pipeline(root_data_dir: str= \"../Data\", data_file_path: str=\"OIL_DATASET.csv\", data_splits_dir: str=\"DataSplits\", scaler_dir = \"Scalers\", batch_size: int=64, num_workers=0, pin_memory: bool=False, drop_last: bool=True) -> tuple[Dataset, Dataset, Dataset, DataLoader, DataLoader, DataLoader, MinMaxScaler, MinMaxScaler]:\n",
    "    \"\"\"This function prepares the train, test, and validation datasets.\n",
    "    Args:\n",
    "        root_data_dir (str): The root of the Data Directory\n",
    "        data_file_path (str): The name of the original dataset (with .csv file extension).\n",
    "        data_splits_dir (str): Path to the train, test, and validation datasets.\n",
    "        scaler_dir (str): Path to the feature and label scalers.\n",
    "        batch_size (int): The dataloader's batch_size.\n",
    "        num_workers (int): The dataloader's number of workers.\n",
    "        pin_memory (bool): The dataloader's pin memory option.\n",
    "        drop_last (bool): The dataloader's drop_last option.\n",
    "\n",
    "    Returns: \n",
    "        train_dataset (Dataset): Dataset Class for the training dataset.\n",
    "        test_dataset (Dataset): Dataset Class for the test dataset.\n",
    "        validation_dataset (Dataset): Dataset Class for the validation dataset.\n",
    "        train_dataloader (DataLoader): The train dataloader.\n",
    "        test_dataloader (DataLoader): The test dataloader.\n",
    "        validation_dataloader (DataLoader): The validation dataloader.\n",
    "        feature_scaler (MinMaxScaler): The scaler used to scale the features of the model input.\n",
    "        label_scaler (MinMaxScaler): The scaler used to scale the labels of the model input.\n",
    "        \"\"\"\n",
    "    if not root_data_dir or not data_file_path or not data_splits_dir:  # Check for empty strings at the beginning\n",
    "        raise ValueError(\"File and directory paths cannot be empty strings.\")\n",
    "    DATA_ROOT = Path(root_data_dir)\n",
    "    # OIL_PATH_ORIGINAL = DATA_ROOT / \"OIL_Dataset_1984-2025.csv\"     # Set the data source path\n",
    "\n",
    "    DATA_CLEAN_PATH = DATA_ROOT / data_file_path # Set the path to the complete dataset\n",
    "\n",
    "    if DATA_CLEAN_PATH.exists():\n",
    "        print(f\"CSV file detected, reading from '{DATA_ROOT}'\")\n",
    "        df = pd.read_csv(DATA_CLEAN_PATH)\n",
    "    else:\n",
    "        print(f\"Downloading CSV file from HuggingFace\")\n",
    "        os.makedirs(DATA_ROOT, exist_ok=True)       # Create the Data Root Directory\n",
    "        df = pd.read_csv(\"hf://datasets/MaxPrestige/CRUDE_OIL_PRICES/Data/OIL_DATASET.csv\")  # Download and read the data into a pandas dataframe\n",
    "        df.to_csv(DATA_CLEAN_PATH, index=False)     # Save the file, omitting saving the index\n",
    "\n",
    "    DATA_SPLITS_DIR = DATA_ROOT / data_splits_dir\n",
    "    SCALER_DIR = DATA_ROOT / scaler_dir\n",
    "\n",
    "    TRAIN_DATA_PATH = DATA_SPLITS_DIR / \"train.csv\"\n",
    "    TEST_DATA_PATH = DATA_SPLITS_DIR / \"test.csv\"\n",
    "    VALIDATION_DATA_PATH = DATA_SPLITS_DIR / \"val.csv\"\n",
    "\n",
    "    FEATURE_SCALER_PATH = SCALER_DIR / \"feature-scaler.joblib\"\n",
    "    LABEL_SCALER_PATH = SCALER_DIR / \"label-scaler.joblib\"\n",
    "\n",
    "    label_col = \"Close\"\n",
    "    extra_dropped_cols = 'Date'\n",
    "\n",
    "    if os.path.exists(TRAIN_DATA_PATH) and os.path.exists(TEST_DATA_PATH) and os.path.exists(VALIDATION_DATA_PATH) :\n",
    "        print(f\"Train, Test, and Validation csv datasets detected in '{DATA_SPLITS_DIR}.' Skipping generation and loading scaler(s)\")\n",
    "        try:\n",
    "            feature_scaler = joblib.load(FEATURE_SCALER_PATH)\n",
    "            label_scaler = joblib.load(LABEL_SCALER_PATH)\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"An unexpected error occurred when loading scalers: {e}\")\n",
    "    else:\n",
    "        print(f\"Datasets not found in '{DATA_SPLITS_DIR}' or incomplete. Generating datasets...\")\n",
    "        # os.makedirs(MODEL_ROOT, exist_ok=True)\n",
    "        os.makedirs(DATA_SPLITS_DIR, exist_ok=True)     # Create the Data Splits Parent Directory\n",
    "        os.makedirs(SCALER_DIR, exist_ok=True)     # Create the Data Splits Parent Directory\n",
    "\n",
    "        feature_scaler = MinMaxScaler()\n",
    "        label_scaler = MinMaxScaler()\n",
    "        # Split the Dataframe into separate features and labels DataFrames\n",
    "        df_features = df.drop(columns=[label_col, extra_dropped_cols], inplace=False)\n",
    "        df_labels = df[[label_col]]     # Instead of returning a pandas Series using \"[]\", return a dataframe using the \"[[]]\" to get a shape with (-1,1)\n",
    "\n",
    "        # Split into smaller DataFrames for the Train, Test, and Validation splits\n",
    "        X_train, X_inter, Y_train, Y_inter = train_test_split(df_features, df_labels, test_size=0.1, random_state=42)\n",
    "        X_validation, X_test, Y_validation, Y_test = train_test_split(X_inter, Y_inter, test_size=0.5, random_state=42)\n",
    "\n",
    "        # print(f\"Train Features: {X_train.shape}\")\n",
    "        # print(f\"Train Labels: {Y_train.shape}\")\n",
    "        # print(f\"validation Features: {X_validation.shape}\")\n",
    "        # print(f\"validation Labels: {Y_validation.shape}\")\n",
    "        # print(f\"test Features: {X_test.shape}\")\n",
    "        # print(f\"test Labels: {Y_test.shape}\")\n",
    "\n",
    "        feature_scaler.fit(X_train)\n",
    "        label_scaler.fit(Y_train)\n",
    "\n",
    "        # Save the fitted scaler object\n",
    "        try:\n",
    "            joblib.dump(feature_scaler, FEATURE_SCALER_PATH)\n",
    "            print(f\"Feature scaler stored in: ({FEATURE_SCALER_PATH})\")\n",
    "            joblib.dump(label_scaler, LABEL_SCALER_PATH)\n",
    "            print(f\"Label scaler stored in: ({LABEL_SCALER_PATH})\")\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"An unexpected error occurred when saving  Scalers: {e}\")\n",
    "\n",
    "        # Scale the rest of the data; returns numpy arrays\n",
    "        X_train_scaled = feature_scaler.transform(X_train)\n",
    "        Y_train_scaled = label_scaler.transform(Y_train)\n",
    "        X_validation_scaled = feature_scaler.transform(X_validation)\n",
    "        Y_validation_scaled = label_scaler.transform(Y_validation)\n",
    "        X_test_scaled = feature_scaler.transform(X_test)\n",
    "        Y_test_scaled = label_scaler.transform(Y_test)\n",
    "\n",
    "        print(f\"Train Features Scaled Shape: {X_train_scaled.shape}\")\n",
    "        print(f\"Train Labels Scaled Shape: {Y_test_scaled.shape}\")\n",
    "        print(f\"validation Features Scaled Shape: {X_validation_scaled.shape}\")\n",
    "        print(f\"validation Labels: {Y_validation_scaled.shape}\")\n",
    "        print(f\"test Features Scaled Shape: {X_test_scaled.shape}\")\n",
    "        print(f\"test Labels Scaled Shape: {Y_test_scaled.shape}\")\n",
    "        # Define the column names of the features and label\n",
    "        features_names = df_features.columns\n",
    "        label_name = df_labels.columns\n",
    "        # Create dataframes using the scaled data\n",
    "        X_train_df = pd.DataFrame(X_train_scaled, columns=features_names)\n",
    "        X_test_df = pd.DataFrame(X_test_scaled, columns=features_names)\n",
    "        X_validation_df = pd.DataFrame(X_validation_scaled, columns=features_names)\n",
    "        Y_train_df = pd.DataFrame(Y_train_scaled, columns=label_name)\n",
    "        Y_test_df = pd.DataFrame(Y_test_scaled, columns=label_name)\n",
    "        Y_validation_df = pd.DataFrame(Y_validation_scaled, columns=label_name)\n",
    "\n",
    "        # Concatenate the features and labels back into a single DataFrame for each set\n",
    "        train_data_frame = pd.concat([X_train_df, Y_train_df.reset_index(drop=True)], axis=1)\n",
    "        test_data_frame = pd.concat([X_test_df, Y_test_df.reset_index(drop=True)], axis=1)\n",
    "        validation_data_frame = pd.concat([X_validation_df, Y_validation_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "        # Saving the split data to csv files\n",
    "        train_data_frame.to_csv(TRAIN_DATA_PATH, index=False)\n",
    "        test_data_frame.to_csv(TEST_DATA_PATH, index=False)\n",
    "        validation_data_frame.to_csv(VALIDATION_DATA_PATH, index=False)\n",
    "    # Creating Datasets from the stored datasets\n",
    "    print(f\"Initializing Datasets\")\n",
    "    train_dataset = OilDataset(TRAIN_DATA_PATH)\n",
    "    test_dataset = OilDataset(TEST_DATA_PATH)\n",
    "    val_dataset = OilDataset(VALIDATION_DATA_PATH)\n",
    "    \n",
    "    print(f\"Creating DataLoaders with batch_size ({batch_size}), num_workers ({num_workers}), pin_memory ({pin_memory}). Training dataset drop_last: ({drop_last})\")\n",
    "    train_dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size, num_workers=workers, pin_memory=pin_memory, drop_last=drop_last, shuffle=True)\n",
    "    validation_dataloader = DataLoader(dataset=val_dataset, batch_size=batch_size, num_workers=workers, pin_memory=pin_memory, drop_last=drop_last, shuffle=False)\n",
    "    test_dataloader = DataLoader(dataset=test_dataset, batch_size=batch_size, num_workers=workers, pin_memory=pin_memory, drop_last=drop_last, shuffle=False)\n",
    "\n",
    "    print(f\"Training DataLoader has ({len(train_dataloader)}) batches, Test DataLoader has ({len(test_dataloader)}) batches, Validation DataLoader has ({len(validation_dataloader)}) batches\")\n",
    "\n",
    "    return (train_dataset, test_dataset, val_dataset, train_dataloader, test_dataloader, validation_dataloader, feature_scaler, label_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3838d663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file detected, reading from '..\\Data'\n",
      "Datasets not found in '..\\Data\\DataSplits' or incomplete. Generating datasets...\n",
      "Feature scaler stored in: (..\\Data\\Scalers\\feature-scaler.joblib)\n",
      "Label scaler stored in: (..\\Data\\Scalers\\label-scaler.joblib)\n",
      "Train Features Scaled Shape: (5727, 22)\n",
      "Train Labels Scaled Shape: (319, 1)\n",
      "validation Features Scaled Shape: (318, 22)\n",
      "validation Labels: (318, 1)\n",
      "test Features Scaled Shape: (319, 22)\n",
      "test Labels Scaled Shape: (319, 1)\n",
      "Initializing Datasets\n",
      "Creating DataLoaders with batch_size (64), num_workers (0), pin_memory (False). Training dataset drop_last: (True)\n",
      "Training DataLoader has (89) batches, Test DataLoader has (4) batches, Validation DataLoader has (4) batches\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    data_pipeline(root_data_dir=\"../Data\", data_file_path=\"OIL_DATASET.csv\", data_splits_dir=\"DataSplits\")\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"An unexpected error occurred when running the data pipeline function:{e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WP_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

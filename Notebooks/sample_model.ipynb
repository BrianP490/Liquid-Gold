{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1c7208c",
   "metadata": {},
   "source": [
    "# Testing Model Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38313aff",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10f3e599",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib.metadata import version\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from torch.nn import Module # For type hinting\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import time\n",
    "import argparse\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbefac4",
   "metadata": {},
   "source": [
    "## Data Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de220668",
   "metadata": {},
   "source": [
    "### Creating Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5fdbbdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OilDataset(Dataset):\n",
    "    \"\"\"Dataset class For the OIL_DATASET\"\"\"\n",
    "    def __init__(self, csv_file=\"../Data/DataSplits/test.csv\"):\n",
    "        try:\n",
    "            self.data = pd.read_csv(csv_file)   # Assign a pandas data frame\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            raise FileNotFoundError(f\"File not found: {csv_file}\")\n",
    "\n",
    "        # Define feature and label columns\n",
    "        self.label_column = \"Close\"\n",
    "        # Remove the Date column and the label column\n",
    "        self.feature_columns = self.data.columns.drop([self.label_column])\n",
    "        \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        features = self.data.loc[index, self.feature_columns].values\n",
    "        \n",
    "        label = self.data.loc[index, self.label_column] # Extract the label for the given index\n",
    "        return (\n",
    "            torch.tensor(features, dtype=torch.float),\n",
    "            torch.tensor(label, dtype=torch.float)\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c9b5c1",
   "metadata": {},
   "source": [
    "### Data Pipeline Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9335a497",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_pipeline(root_data_dir: str= \"../Data\", data_file_path: str=\"OIL_DATASET.csv\", data_splits_dir: str=\"DataSplits\", scaler_dir = \"Scalers\", batch_size: int=64, num_workers=0, pin_memory: bool=False, drop_last: bool=True) -> tuple[Dataset, Dataset, Dataset, DataLoader, DataLoader, DataLoader, MinMaxScaler, MinMaxScaler]:\n",
    "    \"\"\"This function prepares the train, test, and validation datasets.\n",
    "    Args:\n",
    "        root_data_dir (str): The root of the Data Directory\n",
    "        data_file_path (str): The name of the original dataset (with .csv file extension).\n",
    "        data_splits_dir (str): Path to the train, test, and validation datasets.\n",
    "        scaler_dir (str): Path to the feature and label scalers.\n",
    "        batch_size (int): The dataloader's batch_size.\n",
    "        num_workers (int): The dataloader's number of workers.\n",
    "        pin_memory (bool): The dataloader's pin memory option.\n",
    "        drop_last (bool): The dataloader's drop_last option.\n",
    "\n",
    "    Returns: \n",
    "        train_dataset (Dataset): Dataset Class for the training dataset.\n",
    "        test_dataset (Dataset): Dataset Class for the test dataset.\n",
    "        validation_dataset (Dataset): Dataset Class for the validation dataset.\n",
    "        train_dataloader (DataLoader): The train dataloader.\n",
    "        test_dataloader (DataLoader): The test dataloader.\n",
    "        validation_dataloader (DataLoader): The validation dataloader.\n",
    "        feature_scaler (MinMaxScaler): The scaler used to scale the features of the model input.\n",
    "        label_scaler (MinMaxScaler): The scaler used to scale the labels of the model input.\n",
    "        \"\"\"\n",
    "    if not root_data_dir or not data_file_path or not data_splits_dir:  # Check for empty strings at the beginning\n",
    "        raise ValueError(\"File and directory paths cannot be empty strings.\")\n",
    "    DATA_ROOT = Path(root_data_dir)\n",
    "    # OIL_PATH_ORIGINAL = DATA_ROOT / \"OIL_Dataset_1984-2025.csv\"     # Set the data source path\n",
    "\n",
    "    DATA_CLEAN_PATH = DATA_ROOT / data_file_path # Set the path to the complete dataset\n",
    "\n",
    "    if DATA_CLEAN_PATH.exists():\n",
    "        print(f\"CSV file detected, reading from '{DATA_ROOT}'\")\n",
    "        df = pd.read_csv(DATA_CLEAN_PATH)\n",
    "    else:\n",
    "        print(f\"Downloading CSV file from HuggingFace\")\n",
    "        os.makedirs(DATA_ROOT, exist_ok=True)       # Create the Data Root Directory\n",
    "        df = pd.read_csv(\"hf://datasets/MaxPrestige/CRUDE_OIL_PRICES/Data/OIL_DATASET.csv\")  # Download and read the data into a pandas dataframe\n",
    "        df.to_csv(DATA_CLEAN_PATH, index=False)     # Save the file, omitting saving the index\n",
    "\n",
    "    DATA_SPLITS_DIR = DATA_ROOT / data_splits_dir\n",
    "    SCALER_DIR = DATA_ROOT / scaler_dir\n",
    "\n",
    "    TRAIN_DATA_PATH = DATA_SPLITS_DIR / \"train.csv\"\n",
    "    TEST_DATA_PATH = DATA_SPLITS_DIR / \"test.csv\"\n",
    "    VALIDATION_DATA_PATH = DATA_SPLITS_DIR / \"val.csv\"\n",
    "\n",
    "    FEATURE_SCALER_PATH = SCALER_DIR / \"feature-scaler.joblib\"\n",
    "    LABEL_SCALER_PATH = SCALER_DIR / \"label-scaler.joblib\"\n",
    "\n",
    "    label_col = \"Close\"\n",
    "    extra_dropped_cols = 'Date'\n",
    "\n",
    "    if os.path.exists(TRAIN_DATA_PATH) and os.path.exists(TEST_DATA_PATH) and os.path.exists(VALIDATION_DATA_PATH) :\n",
    "        print(f\"Train, Test, and Validation csv datasets detected in '{DATA_SPLITS_DIR}.' Skipping generation and loading scaler(s)\")\n",
    "        try:\n",
    "            feature_scaler = joblib.load(FEATURE_SCALER_PATH)\n",
    "            label_scaler = joblib.load(LABEL_SCALER_PATH)\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"An unexpected error occurred when loading scalers: {e}\")\n",
    "    else:\n",
    "        print(f\"Datasets not found in '{DATA_SPLITS_DIR}' or incomplete. Generating datasets...\")\n",
    "        # os.makedirs(MODEL_ROOT, exist_ok=True)\n",
    "        os.makedirs(DATA_SPLITS_DIR, exist_ok=True)     # Create the Data Splits Parent Directory\n",
    "        os.makedirs(SCALER_DIR, exist_ok=True)     # Create the Scaler Parent Directory\n",
    "\n",
    "        feature_scaler = MinMaxScaler()\n",
    "        label_scaler = MinMaxScaler()\n",
    "        # Split the Dataframe into separate features and labels DataFrames\n",
    "        df_features = df.drop(columns=[label_col, extra_dropped_cols], inplace=False)\n",
    "        df_labels = df[[label_col]]     # Instead of returning a pandas Series using \"[]\", return a dataframe using the \"[[]]\" to get a shape with (-1,1)\n",
    "\n",
    "        # Split into smaller DataFrames for the Train, Test, and Validation splits\n",
    "        X_train, X_inter, Y_train, Y_inter = train_test_split(df_features, df_labels, test_size=0.1, random_state=42)\n",
    "        X_validation, X_test, Y_validation, Y_test = train_test_split(X_inter, Y_inter, test_size=0.5, random_state=42)\n",
    "\n",
    "        feature_scaler.fit(X_train)\n",
    "        label_scaler.fit(Y_train)\n",
    "\n",
    "        # Save the fitted scaler object\n",
    "        try:\n",
    "            joblib.dump(feature_scaler, FEATURE_SCALER_PATH)\n",
    "            print(f\"Feature scaler stored in: ({FEATURE_SCALER_PATH})\")\n",
    "            joblib.dump(label_scaler, LABEL_SCALER_PATH)\n",
    "            print(f\"Label scaler stored in: ({LABEL_SCALER_PATH})\")\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"An unexpected error occurred when saving  Scalers: {e}\")\n",
    "\n",
    "        # Scale the rest of the data; returns numpy arrays\n",
    "        X_train_scaled = feature_scaler.transform(X_train)\n",
    "        Y_train_scaled = label_scaler.transform(Y_train)\n",
    "        X_validation_scaled = feature_scaler.transform(X_validation)\n",
    "        Y_validation_scaled = label_scaler.transform(Y_validation)\n",
    "        X_test_scaled = feature_scaler.transform(X_test)\n",
    "        Y_test_scaled = label_scaler.transform(Y_test)\n",
    "\n",
    "        print(f\"Train Features Scaled Shape: {X_train_scaled.shape}\")\n",
    "        print(f\"Train Labels Scaled Shape: {Y_test_scaled.shape}\")\n",
    "        print(f\"validation Features Scaled Shape: {X_validation_scaled.shape}\")\n",
    "        print(f\"validation Labels: {Y_validation_scaled.shape}\")\n",
    "        print(f\"test Features Scaled Shape: {X_test_scaled.shape}\")\n",
    "        print(f\"test Labels Scaled Shape: {Y_test_scaled.shape}\")\n",
    "        # Define the column names of the features and label\n",
    "        features_names = df_features.columns\n",
    "        label_name = df_labels.columns\n",
    "        # Create dataframes using the scaled data\n",
    "        X_train_df = pd.DataFrame(X_train_scaled, columns=features_names)\n",
    "        X_test_df = pd.DataFrame(X_test_scaled, columns=features_names)\n",
    "        X_validation_df = pd.DataFrame(X_validation_scaled, columns=features_names)\n",
    "        Y_train_df = pd.DataFrame(Y_train_scaled, columns=label_name)\n",
    "        Y_test_df = pd.DataFrame(Y_test_scaled, columns=label_name)\n",
    "        Y_validation_df = pd.DataFrame(Y_validation_scaled, columns=label_name)\n",
    "\n",
    "        # Concatenate the features and labels back into a single DataFrame for each set\n",
    "        train_data_frame = pd.concat([X_train_df, Y_train_df.reset_index(drop=True)], axis=1)\n",
    "        test_data_frame = pd.concat([X_test_df, Y_test_df.reset_index(drop=True)], axis=1)\n",
    "        validation_data_frame = pd.concat([X_validation_df, Y_validation_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "        # Saving the split data to csv files\n",
    "        train_data_frame.to_csv(TRAIN_DATA_PATH, index=False)\n",
    "        test_data_frame.to_csv(TEST_DATA_PATH, index=False)\n",
    "        validation_data_frame.to_csv(VALIDATION_DATA_PATH, index=False)\n",
    "    # Creating Datasets from the stored datasets\n",
    "    print(f\"Initializing Datasets\")\n",
    "    train_dataset = OilDataset(TRAIN_DATA_PATH)\n",
    "    test_dataset = OilDataset(TEST_DATA_PATH)\n",
    "    val_dataset = OilDataset(VALIDATION_DATA_PATH)\n",
    "    \n",
    "    print(f\"Creating DataLoaders with batch_size ({batch_size}), num_workers ({num_workers}), pin_memory ({pin_memory}). Training dataset drop_last: ({drop_last})\")\n",
    "    train_dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size, num_workers=num_workers, pin_memory=pin_memory, drop_last=drop_last, shuffle=True)\n",
    "    validation_dataloader = DataLoader(dataset=val_dataset, batch_size=batch_size, num_workers=num_workers, pin_memory=pin_memory, drop_last=drop_last, shuffle=False)\n",
    "    test_dataloader = DataLoader(dataset=test_dataset, batch_size=batch_size, num_workers=num_workers, pin_memory=pin_memory, drop_last=drop_last, shuffle=False)\n",
    "\n",
    "    print(f\"Training DataLoader has ({len(train_dataloader)}) batches, Test DataLoader has ({len(test_dataloader)}) batches, Validation DataLoader has ({len(validation_dataloader)}) batches\")\n",
    "\n",
    "    return (train_dataset, test_dataset, val_dataset, train_dataloader, test_dataloader, validation_dataloader, feature_scaler, label_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3838d663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file detected, reading from '..\\Data'\n",
      "Train, Test, and Validation csv datasets detected in '..\\Data\\DataSplits.' Skipping generation and loading scaler(s)\n",
      "Initializing Datasets\n",
      "Creating DataLoaders with batch_size (64), num_workers (0), pin_memory (False). Training dataset drop_last: (True)\n",
      "Training DataLoader has (89) batches, Test DataLoader has (4) batches, Validation DataLoader has (4) batches\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    data_pipeline(root_data_dir=\"../Data\", data_file_path=\"OIL_DATASET.csv\", data_splits_dir=\"DataSplits\")\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"An unexpected error occurred when running the data pipeline function:{e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e203af",
   "metadata": {},
   "source": [
    "## Agent Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090e22b8",
   "metadata": {},
   "source": [
    "### Module Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "955cfcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModuleLayer(torch.nn.Module):\n",
    "    \"\"\"Class for the individual layer blocks.\"\"\"\n",
    "    def __init__(self, intermediate_dim=32, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.mod_linear = torch.nn.Linear(intermediate_dim, intermediate_dim)\n",
    "        self.mod_norm = torch.nn.LayerNorm(normalized_shape=intermediate_dim)\n",
    "        self.mod_relu = torch.nn.ReLU()\n",
    "        self.dropout = torch.nn.Dropout(p=dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.mod_linear(x)\n",
    "        x = self.mod_norm(x)\n",
    "        x = self.mod_relu(x)\n",
    "        x = self.dropout(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a9c2e5",
   "metadata": {},
   "source": [
    "### Oil Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0898fff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent(torch.nn.Module):\n",
    "    \"\"\"Class for Agent Structure using multiple Layer Blocks.\"\"\"\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.linear = torch.nn.Linear(in_features=cfg[\"in_dim\"], out_features=cfg[\"intermediate_dim\"])\n",
    "        self.layers = torch.nn.Sequential(*[ModuleLayer(intermediate_dim=cfg[\"intermediate_dim\"], dropout_rate=cfg[\"dropout_rate\"]) for _ in range(cfg[\"num_blocks\"])])\n",
    "        self.out = torch.nn.Linear(in_features=cfg[\"intermediate_dim\"], out_features=cfg[\"out_dim\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        x = self.layers(x)\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619b1106",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbf679b",
   "metadata": {},
   "source": [
    "### Log Iteration Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a05d5d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_iteration(batch_idx: int, total_batches: int, loss_value: float):\n",
    "    \"\"\"Logs the loss of the current batch.\"\"\"\n",
    "    print(f\"Epoch batch [{batch_idx}/{total_batches}] | Loss: {loss_value:.7f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "162971a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_epoch_iteration(epoch: int, avg_epoch_loss: float):\n",
    "    \"\"\"Log Current Metrics accumulated in the current epoch iteration.\n",
    "    Args:\n",
    "        epoch (int): the current iteration\n",
    "        avg_epoch_loss (float): The average loss of the current epoch\n",
    "    Returns:\n",
    "        N/A\n",
    "        \"\"\"\n",
    "    if avg_epoch_loss:\n",
    "        print(f\"=====================  [EPOCH ({epoch}) LOGGING]  =====================\")\n",
    "        print(\"| AVERAGES of THIS EPOCH:\")\n",
    "        print(f\"| ACCUMULATED LOSS: {avg_epoch_loss:.7f}\")\n",
    "        print(f\"===========================================================\")\n",
    "    \n",
    "    else:\n",
    "        print(\"No Data collected for this epoch to log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b44d5f8",
   "metadata": {},
   "source": [
    "### Evaluate Model Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58184545",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model: Module, dataloader: DataLoader, current_epoch: int = None, max_epochs: int=None, device: str = 'cpu') -> float:\n",
    "    \"\"\"\n",
    "    Evaluates the model on a given dataset and returns the average loss.\n",
    "    Args:\n",
    "        model (Module): The Model.\n",
    "        dataloader (DataLoader): The dataloader to calculate average loss with.\n",
    "        current_epoch (int): The current epoch [optional].\n",
    "        max_epochs (int): The maximum number of epochs [optional].\n",
    "        device (str): The device that the calculations will take place on.\n",
    "    Returns:\n",
    "        avg_loss (float): The calculated average loss.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    # loss_fn = torch.nn.MELoss(reduction='sum') # Use reduction='sum' instead of 'mean' for total loss\n",
    "    loss_fn = torch.nn.L1Loss(reduction='sum')\n",
    "    if len(dataloader.dataset) == 0:\n",
    "        print(\"Warning: Evaluation dataset is empty. Skipping evaluation.\")\n",
    "        return float('nan')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_inputs, batch_labels in dataloader:\n",
    "            batch_inputs, batch_labels = batch_inputs.to(device), batch_labels.unsqueeze(dim=-1).to(device)\n",
    "            outputs = model(batch_inputs)\n",
    "            loss = loss_fn(outputs, batch_labels)\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    avg_loss = total_loss / len(dataloader.dataset)     # Calculate the average loss on the dataset\n",
    "\n",
    "    if current_epoch and max_epochs:   # If the function was called in the training loop\n",
    "        print(f\"===================  [Epoch ({current_epoch}/{max_epochs})]  ===================\")\n",
    "        print(f\"Entire Validation Dataset Average Loss: {avg_loss:.4f}\")\n",
    "        print(f\"====================================================\")\n",
    "\n",
    "    else:   # If the function was called outside of the training loop\n",
    "        print(f\"===============================================\")\n",
    "        print(f\"Entire Dataset Average Loss: {avg_loss:.4f} \")\n",
    "        print(f\"=====================================================\")\n",
    "            \n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44fbd9d",
   "metadata": {},
   "source": [
    "### Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591d5dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_config: dict, train_dataloader: DataLoader, validation_dataloader: DataLoader, model: Agent = None, epochs=32, learning_rate=0.0003, max_grad_norm=0.5, log_iterations=10, eval_iterations=10, device=\"cpu\") -> Agent:\n",
    "    \"\"\"The Model Training function.\n",
    "\n",
    "    Args:\n",
    "        model_config (dict): The base configurations for building the policies.\n",
    "        train_dataloader (DataLoader): The dataloader for the training loop.\n",
    "        validation_dataloader (DataLoader): The dataloader for the validation loop.\n",
    "        model (Agent): The model to be trained.\n",
    "        epochs (int): The number of times the outer loop is performed.\n",
    "        learning_rate (float): The hyperparameter that affects how much the model's parameters learn on each update iteration.\n",
    "        max_grad_norm (float): Used to promote numerical stability and prevent exploding gradients.\n",
    "        log_iterations (int): Used to log information about the state of the Agent.\n",
    "        eval_iterations (int): Used to run an evaluation of the Agent.\n",
    "        device (str): The device that the model will be trained on.\n",
    "\n",
    "    Returns: \n",
    "        agent (Module): The Trained Model in evaluation mode.\n",
    "    \"\"\"\n",
    "    print(f\"Training Model on {device} with {epochs} main epochs, {learning_rate} learning rate, max_grad_norm={max_grad_norm}.\")\n",
    "    print(f\"Logging every {log_iterations} epoch iterations, evaluating every {eval_iterations} epoch iterations.\")\n",
    "\n",
    "    agent = (model if model is not None else Agent(model_config)).to(device) # Create agent if nothing was passed, otherwise, create the agent. Send agent to device.\n",
    "\n",
    "    optimizer = torch.optim.AdamW(params=agent.parameters(), lr=learning_rate, weight_decay=0.01)\n",
    "    loss_fn = torch.nn.L1Loss(reduction='mean')      # Define the Loss function\n",
    "\n",
    "\n",
    "    history = {'train_loss': [], 'val_loss': []}\n",
    "\n",
    "    train_dataloader_length = len(train_dataloader)\n",
    "    agent.train()   # Set agent to training mode\n",
    "    for epoch in tqdm(range(epochs), desc=f\">>>>>>>>>>>>>>>>>>>>>\\nMain Epoch (Outer Loop)\", leave=True):\n",
    "\n",
    "        epoch_loss_total = 0.0\n",
    "        for batch_idx, (inputs, labels) in enumerate(tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}/{epochs} - Training\", leave=False)):           # Get a mini-batch of training examples from the dataloader\n",
    "            # optimizer.zero_grad(set_to_none=True)       # Clear the gradients built up; Setting to None to improve performance\n",
    "            optimizer.zero_grad()       # Clear the gradients built up; Setting to None to improve performance\n",
    "\n",
    "            inputs, labels = inputs.to(device), labels.unsqueeze(dim=-1).to(device)   # Move the inputs and labels to the device\n",
    "\n",
    "            agent_outputs = agent(inputs)       # Pass the inputs to the model and get the outputs.\n",
    "\n",
    "            loss = loss_fn(agent_outputs, labels)      # Calculate the mini-batch loss\n",
    "            epoch_loss_total += loss.item()\n",
    "            \n",
    "            loss.backward()         # Calculate the loss with respect to the model parameters\n",
    "            torch.nn.utils.clip_grad_norm_(parameters=agent.parameters(), max_norm=max_grad_norm)   # Prevent the gradients from affecting the model parameters too much and reduce the risk of exploding gradients\n",
    "\n",
    "            optimizer.step()      # Update the model's parameters using the learning rate\n",
    "\n",
    "            # LOGGING LOSS OF CURRENT ITERATION\n",
    "            if (batch_idx + 1) % log_iterations == 0:\n",
    "                log_iteration(batch_idx=(batch_idx + 1), total_batches=train_dataloader_length, loss_value=loss.item())\n",
    "\n",
    "        # CALCULATE AND STORE THE AVERAGE EPOCH LOSS\n",
    "        epoch_avg_loss = epoch_loss_total / train_dataloader_length\n",
    "        history[\"train_loss\"].append(epoch_avg_loss)\n",
    "\n",
    "        # LOG THE AVERAGE LOSS OF THE EPOCH\n",
    "        # log_epoch_iteration(epoch=epoch, avg_epoch_loss=epoch_avg_loss)\n",
    "\n",
    "        # EVALUATE THE MODEL\n",
    "        if (epoch + 1) % eval_iterations == 0:\n",
    "            val_loss = evaluate_model(model=agent, dataloader=validation_dataloader, current_epoch=(epoch + 1), max_epochs=epochs, device=device)\n",
    "            history[\"val_loss\"].append(val_loss)\n",
    "            agent.train()   # Set agent to training mode\n",
    "        \n",
    "    return agent.eval(), history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1949392",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    \"in_dim\": 22,    # Number of Features as input\n",
    "    \"intermediate_dim\": 128,    \n",
    "    \"out_dim\": 1,   \n",
    "    \"num_blocks\": 12,   # Number of reapeating Layer Blocks\n",
    "    \"dropout_rate\": 0.1     # Rate for dropout layer\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4b23eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_policy = Agent(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5dd8cf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_LOCATION = \"./models/Agent.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14feac89",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = torch.load(f=SAVE_LOCATION, weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f4545cb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_policy.load_state_dict(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "69256643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.eval of Agent(\n",
       "  (linear): Linear(in_features=22, out_features=128, bias=True)\n",
       "  (layers): Sequential(\n",
       "    (0): ModuleLayer(\n",
       "      (mod_linear): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (mod_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (mod_relu): ReLU()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): ModuleLayer(\n",
       "      (mod_linear): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (mod_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (mod_relu): ReLU()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): ModuleLayer(\n",
       "      (mod_linear): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (mod_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (mod_relu): ReLU()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): ModuleLayer(\n",
       "      (mod_linear): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (mod_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (mod_relu): ReLU()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): ModuleLayer(\n",
       "      (mod_linear): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (mod_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (mod_relu): ReLU()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): ModuleLayer(\n",
       "      (mod_linear): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (mod_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (mod_relu): ReLU()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): ModuleLayer(\n",
       "      (mod_linear): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (mod_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (mod_relu): ReLU()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): ModuleLayer(\n",
       "      (mod_linear): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (mod_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (mod_relu): ReLU()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): ModuleLayer(\n",
       "      (mod_linear): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (mod_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (mod_relu): ReLU()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): ModuleLayer(\n",
       "      (mod_linear): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (mod_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (mod_relu): ReLU()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): ModuleLayer(\n",
       "      (mod_linear): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (mod_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (mod_relu): ReLU()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): ModuleLayer(\n",
       "      (mod_linear): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (mod_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (mod_relu): ReLU()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (out): Linear(in_features=128, out_features=1, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_policy.eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "163e4b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file detected, reading from '..\\Data'\n",
      "Train, Test, and Validation csv datasets detected in '..\\Data\\DataSplits.' Skipping generation and loading scaler(s)\n",
      "Initializing Datasets\n",
      "Creating DataLoaders with batch_size (64), num_workers (0), pin_memory (False). Training dataset drop_last: (True)\n",
      "Training DataLoader has (89) batches, Test DataLoader has (4) batches, Validation DataLoader has (4) batches\n",
      "\n",
      "TESTING THE TRAINED POLICY:\n",
      "===============================================\n",
      "Entire Dataset Average Loss: 0.1392 \n",
      "=====================================================\n"
     ]
    }
   ],
   "source": [
    "# --- Data Preparation Pipeline --- \n",
    "try:\n",
    "    (train_dataset, test_dataset, validation_dataset, train_dataloader, test_dataloader, validation_dataloader, feature_scaler, label_scaler) = data_pipeline(batch_size=64)\n",
    "except ValueError as e:\n",
    "    print(f\"Caught an error: {e}\")\n",
    "\n",
    "# --- Testing Trained Model --- \n",
    "print(\"\\nTESTING THE TRAINED POLICY:\")\n",
    "test_loss = evaluate_model(model=trained_policy, dataloader=test_dataloader, current_epoch=None, max_epochs=None, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "99ac43e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.8165, 0.8189, 0.8278, 0.8921, 0.7407, 0.7694, 0.4047, 0.7575, 0.0160,\n",
      "        0.4654, 0.6276, 0.4005, 0.5974, 0.1139, 0.0152, 0.4319, 0.7575, 0.4654,\n",
      "        0.4453, 0.6293, 0.7640, 0.7503])\n",
      "Model predicts: 0.38179898262023926 | Actual: 0.8185274004936218\n",
      "tensor([0.3381, 0.3383, 0.3372, 0.4060, 0.3290, 0.3406, 0.8136, 0.5282, 0.0913,\n",
      "        0.2551, 0.2118, 0.7059, 0.3017, 0.7911, 0.5910, 0.7344, 0.4906, 0.2551,\n",
      "        0.2475, 0.2065, 0.3823, 0.2742])\n",
      "Model predicts: 0.38179898262023926 | Actual: 0.345100462436676\n"
     ]
    }
   ],
   "source": [
    "for index in range(2):\n",
    "    (features, label) = test_dataset[index]\n",
    "    print(features)\n",
    "    pred = trained_policy(features)\n",
    "\n",
    "    print(f\"Model predicts: {pred.item()} | Actual: {label}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WP_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
